{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload \n",
    "\n",
    "from connector import DatabaseRedshift\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test small dataframe inserts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'sandbox_ana'\n",
    "table = 'rory_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b         c             d             e        f      g   h      i\n",
      "0  1.0  1.0  1.111111  1.000000e+07  1.000001e+05    hello   True NaN  hello\n",
      "1  2.0  2.0  1.000000           NaN  1.000000e+09      NaN  False NaN  hello\n",
      "2  3.0  3.0  3.333333           NaN  1.000000e+11    hello  False NaN  hello\n",
      "3  4.0  NaN       NaN           NaN           NaN      NaN    NaN NaN  hello\n",
      "4  5.0  6.0  4.444000  1.638400e+11  1.000001e+05  goodbye    NaN NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_ = pd.DataFrame({'a':[1, 2.0, 3, 4, 5], \n",
    "                  'b': [1.0, 2.0, 3.0, np.nan, 6.0], \n",
    "                  'c':[1.11111111, 1.0, 3.333333, np.nan, 4.444], \n",
    "                  'd':[10**7, np.nan, np.nan, np.nan, 40**7], \n",
    "                  'e':[100000.10202020101, 1000000000.20920922, 100000000000.2902902902, np.nan, 100000.089309],\n",
    "                  'f':['hello', np.nan, 'hello', np.nan, 'goodbye'],\n",
    "                  'g':[True, False, False, np.nan, np.nan],\n",
    "                  'h':[np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "                   'i':['hello', 'hello', 'hello', 'hello', np.nan]})\n",
    "print(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df_, schema=schema, table=table, mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df_, schema=schema, table=table, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[\"hello's\", \"goodbye's\"]})\n",
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema=schema, table=table, mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[np.nan, np.nan, np.nan]})\n",
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema=schema, table=table, mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(2000):\n",
    "    frames.append(df_)\n",
    "df_1 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df_, schema=schema, table=table, mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: dataframe index is not unique.\n",
      "Data written to sandbox_ana.rory_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df_1, schema=schema, table=table, mode='append', chunksize=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing large dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_, df_])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.reindex(np.arange(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sandbox_ana.rory_datatypes_test created successfully\n",
      "No name passed to `s3_csv_name` defaulting to 20190916_165345_df.csv\n",
      "Saved dwh/20190916_165345_df.csv to bse-analytics-dev.bseint.io\n",
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema='sandbox_ana', table='rory_datatypes_test', mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b         c             d             e        f      g   h\n",
      "0  1.0  1.0  1.111111  1.000000e+07  1.000001e+05    hello   True NaN\n",
      "1  2.0  2.0       NaN           NaN  1.000000e+09      NaN  False NaN\n",
      "2  3.0  3.0  3.333333           NaN  1.000000e+11    hello  False NaN\n",
      "3  4.0  NaN       NaN           NaN           NaN      NaN    NaN NaN\n",
      "4  5.0  6.0  4.444000  1.638400e+11  1.000001e+05  goodbye    NaN NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[1, 2.0, 3, 4, 5], \n",
    "                  'b': [1.0, 2.0, 3.0, np.nan, 6.0], \n",
    "                  'c':[1.11111111, np.nan, 3.333333, np.nan, 4.444], \n",
    "                  'd':[10**7, np.nan, np.nan, np.nan, 40**7], \n",
    "                  'e':[100000.10202020101, 1000000000.20920922, 100000000000.2902902902, np.nan, 100000.089309],\n",
    "                  'f':['hello', np.nan, 'hello', np.nan, 'goodbye'],\n",
    "                  'g':[True, False, False, np.nan, np.nan],\n",
    "                  'h':[np.nan, np.nan, np.nan, np.nan, np.nan]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df.head(1), schema='sandbox_ana', table='rory_datatypes_test', mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sandbox_ana.rory_datatypes_test created successfully\n",
      "No name passed to `s3_csv_name` defaulting to 20190916_165352_df.csv\n",
      "Saved dwh/20190916_165352_df.csv to bse-analytics-dev.bseint.io\n",
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df.reindex(np.arange(5005)).ffill(), schema='sandbox_ana', table='rory_datatypes_test', mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema='sandbox_ana', table='rory_datatypes_test', mode='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'rory_datatypes_test' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a2c6d0660a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mDatabaseRedshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sandbox_ana'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rory_datatypes_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rory.vigus/repos/analytics-toolkit/database_connector/connector.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, df, schema, table, mode, s3_csv_name, delimiter, index, index_label, chunksize, custom_column_dtypes)\u001b[0m\n\u001b[1;32m    683\u001b[0m                     \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_column_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rory.vigus/repos/analytics-toolkit/database_connector/connector.py\u001b[0m in \u001b[0;36m_basic_insert\u001b[0;34m(self, df, schema, table, mode, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rory.vigus/.virtualenvs/dev/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         sql.to_sql(self, name, con, schema=schema, if_exists=if_exists,\n\u001b[1;32m   2129\u001b[0m                    \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m                    dtype=dtype)\n\u001b[0m\u001b[1;32m   2131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[0;32m/Users/rory.vigus/.virtualenvs/dev/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[1;32m    449\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rory.vigus/.virtualenvs/dev/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1124\u001b[0m                          \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                          schema=schema, dtype=dtype)\n\u001b[0;32m-> 1126\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rory.vigus/.virtualenvs/dev/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table '%s' already exists.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'rory_datatypes_test' already exists."
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema='sandbox_ana', table='rory_datatypes_test', mode='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema='sandbox_ana', table='rory_datatypes_test', mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    df_r = db.fetch(\"select * from sandbox_ana.rory_datatypes_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0        1\n",
      "a  float64  float64\n",
      "b  float64  float64\n",
      "c  float64  float64\n",
      "d  float64  float64\n",
      "e  float64  float64\n",
      "f   object   object\n",
      "g   object   object\n",
      "h  float64  float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df_r.dtypes, df.dtypes], axis=1))\n",
    "# We expect all floats as we have nan's in our data -> pandas automatically converts this to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dtype conversions\n",
    "with DatabaseRedshift() as db:\n",
    "    df = db.fetch(\"select * from sandbox_ana.yanan_bba1597_journey limit 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenceorder         object\n",
      "sku                     int64\n",
      "itemretailpriceeur    float64\n",
      "itemsaleseur          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.blablablalkalalal\n"
     ]
    }
   ],
   "source": [
    "# Test append mode when table does not exist\n",
    "with DatabaseRedshift() as db:\n",
    "    db.insert(df=df, schema='sandbox_ana', table='blablablalkalalal', mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing large dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(np.arange(1, 50000)).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sandbox_ana.rory_datatypes_test created successfully\n",
      "Saved dwh/test.csv to bse-analytics-dev.bseint.io\n",
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(\n",
    "        df=df, schema='sandbox_ana', table='rory_datatypes_test', s3_csv_name='test.csv', mode='replace'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Table sandbox_ana.rory_datatypes_test exists!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7324a96eb17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mDatabaseRedshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     db.insert(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sandbox_ana'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rory_datatypes_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_csv_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fail'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;32m/Users/rory.vigus/repos/analytics-toolkit/database_connector/connector.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, df, schema, table, mode, s3_csv_name, delimiter, index, index_label, chunksize, custom_column_dtypes)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_table_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Table {schema}.{table} exists!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Table sandbox_ana.rory_datatypes_test exists!"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(\n",
    "        df=df, schema='sandbox_ana', table='rory_datatypes_test', s3_csv_name='test.csv', mode='fail'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to sandbox_ana.rory_datatypes_test\n"
     ]
    }
   ],
   "source": [
    "with DatabaseRedshift() as db:\n",
    "    db.insert(\n",
    "        df=df, schema='sandbox_ana', table='rory_datatypes_test', s3_csv_name='test.csv', mode='append'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd_test",
   "language": "python",
   "name": "pd_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
