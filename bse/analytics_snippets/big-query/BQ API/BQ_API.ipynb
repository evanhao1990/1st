{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery API\n",
    "\n",
    "This notebook contains the first draft with code for which we can access BigQuery API. We didn't have time to figure this out completely but it is possible to get data for *simple* queries.\n",
    "\n",
    "Note: The main issue with the BigQuery API is that the queries used in BigQuery console may not work when using the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from pandas.io import gbq\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Example query & dataframe output - using .json file with account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ client - using json downloaded from bigquery/google account\n",
    "bigquery_client = bigquery.Client.from_service_account_json(\"GA-360-BigQuery-API-9e8e351372a6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(\"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        CONCAT(CAST(visitId AS STRING), CAST(fullVisitorId AS STRING)) as session_code,\n",
    "        totals.hits as h,\n",
    "        totals.pageviews as pv,\n",
    "        IF(totals.transactions is not null,totals.transactions,0) as tr\n",
    "    \n",
    "    FROM `ga-360-bigquery-api.113663276.ga_sessions_20180722`\n",
    "\n",
    "    WHERE geoNetwork.country = \"Germany\"\n",
    "  \n",
    "    GROUP BY 1,2,3,4,5\n",
    "    Having pv > 1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date                    session_code  h  pv  tr\n",
      "0  20180722   15322398251898762278104450828  2   2   0\n",
      "1  20180722   15322703553310430775873930695  2   2   0\n",
      "2  20180722   15322554705470727247785870556  2   2   0\n",
      "3  20180722   15322807323449929011709240403  2   2   0\n",
      "4  20180722  153228924411130470864952545023  2   2   0\n"
     ]
    }
   ],
   "source": [
    "results = query_job.result()\n",
    "df = results.to_dataframe()\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Example query & dataframe output - using .json file location (set in enviromental variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago.pimentel\\Desktop\\TATP\\credentials\\GA-360-BigQuery-API-9e8e351372a6.json\n"
     ]
    }
   ],
   "source": [
    "print os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigquery.Client() will look for GOOGLE_APPLICATION_CREDENTIALS in my enviromental variables - contains path of json file with BQ credentials\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = \"\"\"SELECT \n",
    "        date,\n",
    "        CONCAT(CAST(visitId AS STRING), CAST(fullVisitorId AS STRING)) as session_code,\n",
    "        totals.hits as h,\n",
    "        totals.pageviews as pv,\n",
    "        IF(totals.transactions is not null,totals.transactions,0) as tr\n",
    "    FROM `ga-360-bigquery-api.113663276.ga_sessions_20180222`\n",
    "\n",
    "    WHERE geoNetwork.country = 'Germany'\n",
    "  \n",
    "    GROUP BY 1,2,3,4,5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date                   session_code  h  pv  tr\n",
      "0  20180222  15192557221919101246045552810  1 NaN   0\n",
      "1  20180222  15193199983884794609316666749  1 NaN   0\n",
      "2  20180222  15193228935418687525637290864  1 NaN   0\n",
      "3  20180222  15192547138874045374479592624  1 NaN   0\n",
      "4  20180222  15193039961023167456032502821  1 NaN   0\n"
     ]
    }
   ],
   "source": [
    "test_job = client.query(query)\n",
    "res = test_job.result()\n",
    "print res.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example API request - using storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of buckets:  [<Bucket: ana_dim_tables>, <Bucket: bba876>, <Bucket: bse-ga-test>, <Bucket: rory-visitid>, <Bucket: rui_add_basket_analysis>, <Bucket: tiago_test>, <Bucket: ziyan_nfm>]\n",
      "\n",
      "Project ID:  ga-360-bigquery-api\n"
     ]
    }
   ],
   "source": [
    "# Explicitly use service account credentials by specifying the private key\n",
    "storage_client = storage.Client.from_service_account_json(\"GA-360-BigQuery-API-9e8e351372a6.json\")\n",
    "\n",
    "# Make an authenticated API request\n",
    "buckets = list(storage_client.list_buckets())\n",
    "print 'List of buckets: ', buckets\n",
    "print ''\n",
    "print 'Project ID: ', storage_client.project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extras\n",
    "\n",
    "Messy code with some tests which, for now, do not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Example query - works in BQ console but not in API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BQ query from txt file\n",
    "cwd = os.getcwd()\n",
    "top_folder = os.path.dirname(cwd)\n",
    "data_folder = os.path.join(top_folder,'BQ API')\n",
    "bq_file = os.path.join(data_folder, 'bq_test.txt')\n",
    "\n",
    "myfile = open(bq_file)\n",
    "query = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading time analysis\n",
      "# group sessions per average loading time\n",
      "# average page views, pdps and plps\n",
      "# average conversion rate\n",
      "\n",
      "SELECT\n",
      "case when master.avg_load_time < 1.5 then '1-1.5'\n",
      "    when master.avg_load_time between 1.5 and 2 then '1.5-2'\n",
      "    when master.avg_load_time between 2.0 and 2.5 then '2-2.5'\n",
      "    when master.avg_load_time between 2.5 and 3 then '2.5-3'\n",
      "    when master.avg_load_time between 3 and 3.5 then '3-3.5'\n",
      "    when master.avg_load_time between 3.5 and 4 then '3.5-4'\n",
      "    when master.avg_load_time between 4 and 4.5 then '4-4.5'\n",
      "    when master.avg_load_time between 4.5 and 5 then '4.5-5'\n",
      "    when master.avg_load_time between 5 and 5.5 then '5-5.5'\n",
      "    when master.avg_load_time between 5.5 and 6 then '5.5-6'\n",
      "    when master.avg_load_time between 6 and 6.5 then '6-6.5'\n",
      "    when master.avg_load_time between 6.5 and 7 then '6.5-7'\n",
      "    when master.avg_load_time between 7 and 7.5 then '7-7.5'\n",
      "    when master.avg_load_time between 7.5 and 8 then '7.5-8'\n",
      "    when master.avg_load_time between 8 and 8.5 then '8-8.5'\n",
      "    when master.avg_load_time between 8.5 and 9 then '8.5-9'\n",
      "    when master.avg_load_time between 9 and 9.5 then '9-9.5'\n",
      "    when master.avg_load_time between 9.5 and 10 then '9.5-10'\n",
      "    else '>11' end as loading_time_group,\n",
      "    \n",
      "count(master.session_code) as number_sessions,\n",
      "sum(master.pv)/count(master.session_code) as pv_per_sess,\n",
      "sum(master.PLPs)/count(master.session_code) as PLPs_per_session,\n",
      "sum(master.PDPs)/count(master.session_code) as PDPs_per_session,\n",
      "sum(master.tr)/count(master.session_code) as conversion\n",
      "\n",
      "FROM (\n",
      "      SELECT\n",
      "      date,\n",
      "      \n",
      "      CONCAT(CAST(visitId AS STRING), CAST(fullVisitorId AS STRING)) as session_code,\n",
      "      \n",
      "      totals.hits as h,\n",
      "      totals.pageviews as pv,\n",
      "      IF(totals.transactions is not null,totals.transactions,0) as tr,\n",
      "      \n",
      "      # average loading time per event (site speed event) sum of loading time on events in session (seconds) / number of events with time in session\n",
      "      (sum(IF(hits.type = 'EVENT' AND hits.eventInfo.eventCategory ='Site speed', hits.eventInfo.eventValue, 0))/1000) / \n",
      "        sum(IF(hits.type = 'EVENT' AND hits.eventInfo.eventCategory ='Site speed', 1, 0)) as avg_load_time,\n",
      "\n",
      "      count(IF(hits.product.productListName = 'main',hits.product.productListPosition,null)) as PLPs,\n",
      "      count(IF(hits.product.productListName = 'packshot', hits.product.productListPosition, null)) as PDPs\n",
      "\n",
      "      FROM (TABLE_DATE_RANGE([ga-360-bigquery-api:112804024.ga_sessions_], TIMESTAMP('2018-02-03'), TIMESTAMP('2018-02-15')))\n",
      "\n",
      "      group by 1,2,3,4,5\n",
      "     ) master\n",
      "\n",
      "Where master.PLPs > 0\n",
      "  and master.avg_load_time between 1 and 10\n",
      "group by 1\n",
      "order by 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Syntax error: Expected \",\" or \"]\" but got \":\" at [50:50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f90324e197c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ecommerce\\lib\\site-packages\\google\\cloud\\bigquery\\job.pyc\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout, retry)\u001b[0m\n\u001b[0;32m   2641\u001b[0m             \u001b[1;32mnot\u001b[0m \u001b[0mcomplete\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m         \"\"\"\n\u001b[1;32m-> 2643\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2644\u001b[0m         \u001b[1;31m# Return an iterator instead of returning the job.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ecommerce\\lib\\site-packages\\google\\cloud\\bigquery\\job.pyc\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[1;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ecommerce\\lib\\site-packages\\google\\api_core\\future\\polling.pyc\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 Syntax error: Expected \",\" or \"]\" but got \":\" at [50:50]"
     ]
    }
   ],
   "source": [
    "test_job = client.query(query)\n",
    "res = test_job.result()\n",
    "res.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
